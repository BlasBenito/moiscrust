---
classoption: table
title: |
  | MOISCRUST:
  | a soil moisture database 
  | from a Mediterranean semiarid dryland 
  | from 2006 to 2020
  | SUPPLEMENTARY MATERIAL
institute:
  - margalef: "Instituto Multidisciplinar para el Estudio del Medio “Ramon Margalef”, Universidad de Alicante, Edificio Nuevos Institutos, Carretera de San Vicente del Raspeig s/n, 03690 San Vicente del Raspeig, Spain."
  - crowther: "Institut Department of Environmental Systems Science, ETH Zürich. Universitätstrasse 16, 8092 Zurich, Switzerland."
  - ecology: "Departamento de Ecología, Universidad de Alicante, Carretera de San Vicente del Raspeig s/n, 03690 San Vicente del Raspeig, Alicante, Spain."
author:
  - Joaquín Moreno:
       institute: [margalef]
  - Sergio Asensio:
      institute: [margalef]
  - Miguel Berdugo:
      institute: [margalef, crowther]
  - Beatriz Gozalo:
      institute: [margalef]
  - Victoria Ochoa:
      institute: [margalef] 
  - Blas M. Benito:
      institute: [margalef]
  - Fernando T. Maestre:
      institute: [margalef, ecology] 
output:
  pdf_document:
    fig_caption: yes
    fig_width: 9
    highlight: tango
    includes:
      in_header: header.tex
    keep_tex: yes
    latex_engine: lualatex
    number_sections: yes
    toc: yes
    toc_depth: 1
    df_print: kable
    pandoc_args:
      - '--lua-filter=scholarly-metadata.lua'
      - '--lua-filter=author-info-blocks.lua'
  html_document:
    theme: cerulean
    fig_caption: yes
    highlight: tango
    toc: yes
    toc_depth: 1
    number_sections: yes
    pandoc_args:
      - '--lua-filter=scholarly-metadata.lua'
      - '--lua-filter=author-info-blocks.lua'
code_folding: show
citation_package: natbib
urlcolor: blue
linkcolor: blue
toc-title: "Table of contents"
---

\newpage

# Summary

The **MOISCRUST** database contains volumetric water content (VWC, m³/m³) measures taken by soil moisture sensors EC-5 (Decagon Devices Inc., Pullman, USA) every 120 minutes (17th November 2006 to 31th January 2017) and 150 minutes (1st February 2017 to 16th December 2020) from three replicates in five different microsites (*Stipa* tussocks, *Retama* shrubs, and areas with bare soil, and medium and high cover of biocrust-forming lichens) located in The Aranjuez Experimental Station (central Iberian Peninsula, 40⁰02’ N, 3⁰32’W; 590 m.a.s.l). During the long time-span these sensors have been working, there have been periods when data capture has not possible due to technical issues, and as consequence, 34.63% of the database records are missing entries. This reproducible notebook describes in detail the method used to impute missing data in the **MOISCRUST** database.

The **MOISCRUST** database and this reproducible notebook are distributed under the license [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International](https://creativecommons.org/licenses/by/4.0/legalcode).

# Reproducing this notebook

This reproducible workflow is available as an interactive Rstudio notebook in the file **moiscrust.Rmd** stored in this repository. It is packaged with [renv](https://cran.r-project.org/package=renv) to facilitate reproducibility. That means that the R package versions originally used to run the notebook are already installed in the `renv` folder of the repository. To run it in your computer, execute the code chunk below to prepare the session. You will need to replace `eval = FALSE` with `eval = TRUE` in the header of the code chunk.

```{r, eval = FALSE}
install.packages("renv")
library(renv)
renv::restore()
```

# Data loading and preparation

## Installing and loading the required libraries

The following R libraries are required to run this notebook.

```{r, eval = TRUE, message = FALSE, error = FALSE, warning = FALSE}
#automatic install of packages if they are not readily available
required_packages <- c(
  "data.table",
  "dplyr",
  "magrittr",
  "tidyr",
  "ggplot2",
  "kableExtra",
  "foreach",
  "doParallel",
  "readr",
  "writexl",
  "RSQLite",
  "zip",
  "knitr",
  "DBI"
)

#loading packages
library("data.table")
library("dplyr")
library("magrittr")
library("tidyr")
library("ggplot2")
library("kableExtra")
library("foreach")
library("doParallel")
library("readr")
library("writexl")
library("RSQLite")
library("zip")
library("knitr")
library("DBI")

#removing objects
rm(required_packages)
```

## Loading and preparing the raw data

The raw data, stored in the file *moiscrust_raw.csv* was compiled by the members of [Maestre Lab](https://maestrelab.com/en/) from the data provided by the soil moisture sensors.

```{r, eval = TRUE}
#loading the raw moiscrust dataset
moiscrust <- data.table::fread(file = "data/moiscrust_raw.csv") %>% 
  as.data.frame()
```


## Formatting dates and times

The raw data contains two fields representing time, namely *date* (year, month, and day), and *time* (hour, minute, and seconds). Below we format these fields according to the POSIX standard, and add new fields adding criteria to subset the data by time: 

  + *date_time*: Date and time in POSIX format.
  + *date_time_id*: Unique identificator for each *date_time*.
  + *year*: Year number.
  + *year_day*: Day of the year.
  + *month*: Month number.
  + *month_day*: Day of the month.
  + *week*: Week of the year.
  + *week_day*: Day of the week.

```{r, eval = TRUE}
#date to Year-month-day
moiscrust$date <- format(
  as.POSIXct(
    strptime(
      moiscrust$date,
      "%d/%m/%Y",
      tz = ""
      )
    ),
  format = "%Y-%m-%d"
  )

#time to Hour-Minute
moiscrust$time <- format(
  as.POSIXct(
    strptime(
      moiscrust$time,
      "%H:%M:%S",
      tz = ""
      )
    ),
  format = "%H:%M"
  )

#joining date and time
moiscrust$date_time <- as.POSIXct(
  paste(
    moiscrust$date, 
    moiscrust$time
    ), 
  format="%Y-%m-%d %H:%M"
  )

#unique id for each observation
moiscrust$date_time_id <- 1:nrow(moiscrust)

#creating year, month, and day related columns
moiscrust$year <- lubridate::year(moiscrust$date)
moiscrust$year_day <- lubridate::yday(moiscrust$date)
moiscrust$month <- lubridate::month(moiscrust$date)
moiscrust$month_day <- lubridate::mday(moiscrust$date)
moiscrust$week <- lubridate::week(moiscrust$date)
moiscrust$week_day <- lubridate::wday(moiscrust$date)
```

## Reordering columns and arranging into long format

At this point, the *MOISCRUST* data has 15 columns representing soils moisture measures (five microsites per three replicates per microsite), and 10 columns representing *time*. The data is also structured in what is known as a ["wide format"](https://sejdemyr.github.io/r-tutorials/basics/wide-and-long/). Below we reorder these columns to facilitate arranging the data into a "long format".

```{r, eval = TRUE}
#names of the sensors
sensors <- c(
  "retama_1",
  "retama_2",
  "retama_3",
  "stipa_1",
  "stipa_2",
  "stipa_3",
  "bare_soil_1",
  "bare_soil_2",
  "bare_soil_3",
  "biocrust_medium_1",
  "biocrust_medium_2",
  "biocrust_medium_3",
  "biocrust_high_1",
  "biocrust_high_2",
  "biocrust_high_3"
)

#reordering columns of moiscrust to have time in the left side
moiscrust <- moiscrust[, c(
  "date_time",
  "date_time_id",
  "date",
  "time",
  "year",
  "year_day",
  "month",
  "month_day",
  "week",
  "week_day",
  sensors
)]

#to long format
moiscrust_long <- tidyr::pivot_longer(
  moiscrust,
  cols = all_of(sensors),
  names_to = "sensor",
  values_to = "soil_moisture"
)
```

```{r, echo = FALSE, eval = TRUE}
kableExtra::kbl(
  head(
    moiscrust_long, 
    20
    )
  ) %>% 
  kableExtra::kable_styling(
    position = "center", 
    latex_options = c(
      "HOLD_position", 
      "repeat_header", 
      "scale_down"
      ), 
    bootstrap_options = c(
      "hover"
      )
    )
```

## Visualization of the raw data

Having the data in long format facilitates plotting and manipulation. The figure below shows the raw data, with missing data represented by the white color.

```{r, fig.width=12, fig.height=17, eval = TRUE}
ggplot(moiscrust_long) + 
  facet_wrap(
    "year", 
    scales = "free_x", 
    ncol = 2
    ) +
  aes(
    x = year_day, 
    y = sensor, 
    fill = soil_moisture
    ) + 
  geom_tile() + 
  coord_cartesian(expand = FALSE) +
  theme_bw() + 
  scale_fill_viridis_c(
    direction = -1, 
    na.value = "white", 
    option = "B"
    ) + 
  theme(legend.position = "bottom") + 
  ylab("") + 
  xlab("Day of the year") +
  ggtitle("MOISCRUST database (raw data)") +
  labs(fill = expression("Volumetric water content (m³ water / m³ soil)")) + 
  theme(legend.key.width = unit(1, "cm"))
```

## Number of NA per sensor

Due to technical constraints, there is a large number of missing data in the *MOISCRUST* dataset. To better understand the extent of such missing data, the code below counts the number of missing entries per sensor.

```{r, eval = TRUE, error = FALSE, warning = FALSE, message = FALSE}
#counting NA values per sensor
moiscrust_NA <- moiscrust_long %>% 
  group_by(sensor) %>% 
  summarise(na_count = sum(is.na(soil_moisture))) %>% 
  mutate(na_count_percent = round((na_count * 100) / nrow(moiscrust), 1))

#adding sensor microsite to the moiscrust_NA data frame
moiscrust_NA$microsite <- c(
  "bare_soil",
  "bare_soil",
  "bare_soil",
  "biocrust_high",
  "biocrust_high",
  "biocrust_high",
  "biocrust_medium",
  "biocrust_medium",
  "biocrust_medium",
  "retama",
  "retama",
  "retama",
  "stipa",
  "stipa",
  "stipa"
)

#reordering columns and arranging by na_count
moiscrust_NA <- moiscrust_NA[, c(
  "sensor", 
  "microsite", 
  "na_count", 
  "na_count_percent"
  )] %>% 
  dplyr::arrange(na_count) %>% 
  as.data.frame()
```

```{r, eval = TRUE, echo = FALSE}
#showing the table
kableExtra::kbl(moiscrust_NA) %>% 
  kable_styling(
    position = "center", 
    latex_options = c("HOLD_position", "repeat_header"), 
    bootstrap_options = c("hover")
    )
```

# Imputation of missing data

The imputation we apply to fill gaps in *MOISCRUST* works by finding, for a given entry $y$ with missing data at a time $t$, the sensor $x$ with data for $t$ that is in the same type of microsite (if possible), has the longest extent in common, and the highest correlation with the sensor to which $y$ belongs, and estimates $y$ with the linear model $y ~ x$.

## Developing criteria to find candidates for gap filling

To generate the criteria to find the best possible candidate *x* to estimate the missing data *y*, we compute the common length and correlation between all pairs of sensors, and generate a column indicating whether they belong to the same microsite or not. With the values stored in these columns we compute a *selection score* based on the following expression:

$$S_{x} = \%vc_{x, y} + (R_{x, y}^2 * 100) + \left\{
\begin{array}{ll}
      100, & \mbox{if $microsite_{x} == microsite_{y}$}\\
      0, & \mbox{otherwise}
\end{array}
\right. $$

Where:

+ $y$ is the sensor with a missing value to be estimated.
+ $x$ is the sensor to be used as candidate predictor to estimate the missing value in $y$.
+ $S_{x}$ is the selection score of the candidate sensor $x$, in the range [0, 300].
+ $\%vc_{x, y}$ is the percent of common valid cases of the sensors $x$ and $y$.
+ $R_{x, y}^2$ is the Pearson's R² of the common valid cases of the sensors $x$ and $y$.
+ $microsite_{x}$ and $microsite_{y}$ are the respective microsites of the sensors $x$ and $y$.

During data imputation, for each missing value, the sensor with the higher selection score is used to estimate it. 

These criteria are stored in the data frame **sensors_pairs**. Along with the computation of the selection score, the code below also computes a linear model for each pair $x ~ y$, and stores it in the object **sensors_pairs_models**. The identificators of these models are stored in the column *model_id* of the data frame **sensors_pairs**.


```{r, eval = TRUE}
#combining sensors in pairs x-y
sensors_pairs <- combn(
  x = sensors,
  m = 2
) %>% 
  t() %>% 
  as.data.frame()

#adding combinations y-x so all pairs have both directions
#removing repeated pairs
#joining with moiscrust_NA to get sensor groups
#add column same_microsite to check if x and y are or not in the same sensor group
#add empty columns to store % of shared data, model's R squared, and model ID
sensors_pairs <- sensors_pairs %>% 
  rbind(
    data.frame(
      V1 = sensors_pairs$V2,
      V2 = sensors_pairs$V1
    )
  ) %>% 
  distinct(
    V1, 
    V2, 
    .keep_all = TRUE
  ) %>% 
  left_join(
    moiscrust_NA[, c("sensor", "microsite")],
    by = c("V1" = "sensor")
  ) %>% 
  left_join(
    moiscrust_NA[, c("sensor", "microsite")],
    by = c("V2" = "sensor")
  ) %>% 
  rename(
    y = V1,
    x = V2,
    y_microsite = microsite.x, #not a mistake
    x_microsite = microsite.y, #not a mistake
  ) %>% 
  mutate(
    same_microsite = ifelse(
      x_microsite == y_microsite, 
      TRUE, 
      FALSE
      ),
    sensors_shared_valid_percent = NA,
    sensors_r_squared = NA,
    model_id = row_number()
  ) 

#list to store models
sensors_pairs_models <- list()

#looping through sensors pairs to:
#fit lm model y ~ x and save it in sensors_pairs_models
#
for(i in 1:nrow(sensors_pairs)){
  
  #names of the sensors y and x
  y_i <- sensors_pairs[i, "y"]
  x_i <- sensors_pairs[i, "x"]
  
  #data of the sensor pair
  sensor_pair_i <- moiscrust[, c(y_i, x_i)]
  
  #complete cases of the sensor pair
  sensor_pair_i <- sensor_pair_i[complete.cases(sensor_pair_i), ]
   
  #common cases
  sensors_pairs[i, "sensors_shared_valid_percent"] <- 
    nrow(sensor_pair_i) / nrow(moiscrust) * 100
  
  #R squared of the sensor pair
  sensors_pairs[i, "sensors_r_squared"] <- cor(
    sensor_pair_i[, 1],
    sensor_pair_i[, 2]
    )
  
  #model formula y ~ x
  formula_i <- as.formula(paste(y_i, "~", x_i))
  
  #linear model
  sensors_pairs_models[[i]] <- lm(
    formula = formula_i,
    data = sensor_pair_i
  )
  
}

#selection score to find candidates during gap filling 
#(sensors_r_squared * 100) +
#sensors_shared_valid_percent + 
#same_microsite (TRUE = 100, FALSE = 0)
sensors_pairs <- mutate(
  sensors_pairs,
  selection_score = 
    (sensors_r_squared * 100) + 
    sensors_shared_valid_percent + 
    ifelse(same_microsite == TRUE, 100, 0)
)

#removing objects we don't need
rm(
  sensor_pair_i,
  formula_i,
  i,
  x_i,
  y_i
)
```

The resulting data frame, named **sensors_pairs**, has columns with the names of the sensor *y* (the one with missing data to impute), the sensor *x* (the candidate to be used as predictor to estimate *y*), their respective microsites, a column indicating if they belong to the same microsite, the percent of shared valid data, the R squared of their shared data, a 

```{r, eval = TRUE, echo = FALSE}
#showing the table
kableExtra::kbl(
  head(
    sensors_pairs, 
    20
    )
  ) %>% 
  kable_styling(
    position = "center", 
    latex_options = c(
      "HOLD_position", 
      "repeat_header",
      "scale_down"
      ), 
    bootstrap_options = c(
      "hover"
      )
    )
```

## Generating the x and y matrices to impute missing values

During data imputation, two data frames are needed. The data frame **x** contains the data of every sensor for every available time, while the data frame **y**, which starts with empty values, is where the imputed values, their confidence intervals, selection criteria, and other quality-related columns are going to be stored.

```{r, eval = TRUE}
#creating data frame of predictors
x <- moiscrust[, sensors]

#creating data frame to store model results
y <- matrix(
  data = NA, 
  nrow = nrow(moiscrust), 
  ncol = 12
  ) %>% 
  as.data.frame()

#new colnames
colnames(y) <- c(
  "interpolated",
  "model_estimate", 
  "model_ci_lower", 
  "model_ci_upper", 
  "model_predictor",
  "same_microsite",
  "sensors_r_squared",
  "sensors_shared_valid_percent",
  "selection_score",
  "date_time_id",
  "sensor",
  "microsite"
  )

#transferring time id
y[, "date_time_id"] <- moiscrust[, "date_time_id"]
y[, "interpolated"] <- FALSE
```

The **x** data frame looks as follows: 

```{r, eval = TRUE, echo = FALSE}
#showing the table
kableExtra::kbl(head(x, 20)) %>% 
  kable_styling(
    position = "center", 
    latex_options = c(
      "HOLD_position", 
      "repeat_header",
      "scale_down"
      ), 
    bootstrap_options = c(
      "hover"
      )
    )
```

And this is the **y** data frame, that will be filled during data imputation:

```{r, eval = TRUE, echo = FALSE}
#showing the table
kableExtra::kbl(head(y, 20)) %>% 
  kable_styling(
    position = "center", 
    latex_options = c(
      "HOLD_position", 
      "repeat_header",
      "scale_down"
      ), 
    bootstrap_options = c(
      "hover"
      )
    )
```

## Data imputation, step by step

The steps to fill the gaps in the **MOISCRUST** database go as follows:

**1.** A given sensor name is selected: "retama_2"

```{r, eval = TRUE}
sensor = "retama_2"
```

**2.** The sensors pairs from the table **sensors_pairs** where the selected sensor is *y* (the sensor which values are to be imputed) are selected.

```{r, eval = TRUE}
sensors_pair <- sensors_pairs %>% 
    dplyr::filter(y == sensor)
```

```{r, echo = FALSE, eval = TRUE}
kableExtra::kbl(sensors_pair) %>% 
  kable_styling(
    position = "center", 
    latex_options = c(
      "HOLD_position", 
      "repeat_header",
      "scale_down"
      ), 
    bootstrap_options = c(
      "hover"
      )
    )
```

**3.** The first row of the data frame **x** is selected.

```{r, eval = TRUE}
x_row <- x[1, ]
```

```{r, echo = FALSE, eval = TRUE}
kableExtra::kbl(x[1, ]) %>% 
  kable_styling(
    position = "center", 
    latex_options = c(
      "HOLD_position", 
      "repeat_header",
      "scale_down"
      ), 
    bootstrap_options = c(
      "hover"
      )
    )
```

**3.1.** If there is a valid value of soil moisture for the sensor "stipa5063", the algorithm goes to the next row, until there is a row with a missing value.

**4.** If there is a missing value (*NA*), the potential candidate predictors are selected from the row by removing the data of other sensors with *NA*, and the data of the target sensor.

```{r, eval = TRUE}
predictor_candidates <- as.vector(x[1, ])
predictor_candidates <- predictor_candidates[which(
      !is.na(predictor_candidates) & 
        names(predictor_candidates) != sensor
      )]
```

```{r, echo = FALSE, eval = TRUE}
kableExtra::kbl(predictor_candidates) %>% 
  kable_styling(
    position = "center", 
    latex_options = c(
      "HOLD_position", 
      "repeat_header"
      ), 
    bootstrap_options = c(
      "hover"
      )
    )
```

**5.** From these predictors, the one with the highest selection score is selected from the data frame **sensors_pair** generated in the step **2.**.

```{r, eval = TRUE}
best_predictor <- sensors_pair %>% 
  dplyr::filter(x %in% names(predictor_candidates)) %>%
  dplyr::arrange(desc(selection_score)) %>% 
  dplyr::slice(1)
```

```{r, echo = FALSE, eval = TRUE}
kableExtra::kbl(best_predictor) %>% 
  kable_styling(
    position = "center", 
    latex_options = c(
      "HOLD_position", 
      "repeat_header",
      "scale_down"
      ), 
    bootstrap_options = c(
      "hover"
      )
    )
```

**6.** The model to use, stored in the list **sensors_pairs_model**, is selected from *model_id* column of the **best_predictor** data frame , and used to predict a value for the empty cell.

```{r, eval = TRUE}
predict(
  object = sensors_pairs_models[[best_predictor$model_id]],
  newdata = x_row,
  se.fit = TRUE,
  type = "response",
  interval = "confidence"
  )$fit
```

**7.** The imputed value, its confidence intervals, and other values about the imputation quality available in **best_predictor** are transferred to the same row in the data frame **y**.

**8.** Once all the sensors and rows have been processed this way, the matrix **y** is joined with **moiscrust_long**, and its interpolated values are transferred to the *soil_moisture* column, along with other columns indicating the quality of the interpolation.

## Applying the imputation algorithm to the complete dataset

The code below applies the algorithm to every sensor and row with missing data. Sensors are processed in parallel to speed up the data imputation operation.

```{r, eval = TRUE}
#setup for parallel execution
temp_cluster <- parallel::makeCluster(
  parallel::detectCores() - 1,
  type = "PSOCK"
)
doParallel::registerDoParallel(cl = temp_cluster)
    
#parallelized loop (each sensor is processed in one separated thread)
moiscrust_interpolation <- foreach::foreach(
  sensor_i = sensors,
  .packages = c("magrittr", "dplyr")
) %dopar% {
  
  #subset sensors_pairs
  sensors_pair_i <- sensors_pairs %>% 
    dplyr::filter(y == sensor_i)
  
  #fill microsite
  y[, "microsite"] <-sensors_pair_i$y_microsite[1]
  
  #scanning the rows of x one by one
  for(row_i in 1:nrow(x)){
    
    #if is not NA, next iteration
    if(!is.na(x[row_i, sensor_i])){next}
    
    #getting target row row
    x_row_i <- x[row_i, ]
    
    #getting predictor candidates available in x_row_i
    predictor_candidates_i <- as.vector(x_row_i)
    predictor_candidates_i <- predictor_candidates_i[which(
      !is.na(predictor_candidates_i) & 
        names(predictor_candidates_i) != sensor_i
      )]
    
    #selecting the predictor candidate with the best selection_score score
    best_predictor_i <- sensors_pair_i %>% 
      dplyr::filter(x %in% names(predictor_candidates_i)) %>%
      dplyr::arrange(desc(selection_score)) %>% 
      dplyr::slice(1)
    
    #if there is no best candidate available, next iteration
    if(nrow(best_predictor_i) == 0){next}
    
    #compute estimates with the model of the best predictor
    y[row_i, c(
      "model_estimate", 
      "model_ci_lower", 
      "model_ci_upper"
      )] <- predict(
        object = sensors_pairs_models[[best_predictor_i$model_id]],
        newdata = x_row_i,
        se.fit = TRUE,
        type = "response",
        interval = "confidence"
        )$fit
    
    #adding interpolation flag
    y[row_i, "interpolated"] <- TRUE
    y[row_i, "model_predictor"] <- best_predictor_i$x
    y[row_i, "sensors_r_squared"] <- best_predictor_i$sensors_r_squared
    y[row_i, "selection_score"] <- best_predictor_i$selection_score
    y[row_i, "sensors_shared_valid_percent"] <- best_predictor_i$sensors_shared_valid_percent
    y[row_i, "same_microsite"] <- best_predictor_i$same_microsite
    
  }
  
  #adding sensor_i name
  y[, "sensor"] <- sensor_i
  
  return(y)
  
}

#stop cluster
parallel::stopCluster(temp_cluster)

#removing loop objects
rm(
  x,
  y,
  temp_cluster
)
```

The imputation algorithm produces a list named **moiscrust_interpolation**, with one slot per sensor, each one with one **y** data frame containing the imputation results. Below we transform this object into the data frame **moiscrust_interpolation_long** and join it with **moiscrust_long**, to start preparing the database format.

```{r, eval = TRUE, error = FALSE, warning = FALSE, message = FALSE}
#naming the output
names(moiscrust_interpolation) <- sensors

#to data frame
moiscrust_interpolation_long <- do.call(
  "rbind",
  moiscrust_interpolation
)

#joining with moiscrust_long
moiscrust_long <- dplyr::left_join(
  moiscrust_long,
  moiscrust_interpolation_long,
  by = c("date_time_id", "sensor")
)

#transferring estimates to the soil_moisture column
moiscrust_long$soil_moisture <- ifelse(
  is.na(moiscrust_long$soil_moisture), 
  moiscrust_long$model_estimate, 
  moiscrust_long$soil_moisture
)

#adding a interpolation_quality flag following the criteria in the paper
moiscrust_long$interpolation_quality <- ifelse(
  moiscrust_long$sensors_r_squared > 0.85 &
  moiscrust_long$sensors_shared_valid_percent > 20,
  "acceptable",
  "poor"
)

#filling NA with "observation"
moiscrust_long[
  is.na(moiscrust_long$interpolation_quality), "interpolation_quality"
  ] <- "observation"

#adding NA where there are no values
moiscrust_long[is.na(moiscrust_long$soil_moisture), "interpolation_quality"] <- NA

#computing number of NA cases again
moiscrust_NA <- moiscrust_long %>% 
  group_by(sensor) %>% 
  summarise(na_count_after = sum(is.na(soil_moisture))) %>% 
  mutate(na_count_percent_after = round((na_count_after * 100) / nrow(moiscrust), 1)) %>% 
  left_join(
    y = moiscrust_NA,
    by = "sensor"
  ) %>% 
  transmute(
    sensor,
    na_count_before = na_count,
    na_count_after,
    na_count_percent_before = na_count_percent,
    na_count_percent_after
  )

#removing moiscrust_interpolation
rm(moiscrust_interpolation)
```

The interpolation has removed all gaps where there was a value to interpolate from, as shown in the table below.

```{r, eval = TRUE, echo = FALSE}
kableExtra::kbl(
  moiscrust_NA, 
  col.names = c(
    "Sensor",
    "NA before interpolation",
    "NA after interpolation",
    "NA % before interpolation",
    "NA % after interpolation"
    )
  ) %>% 
  kable_styling(
    position = "center", 
    latex_options = c(
      "HOLD_position", 
      "repeat_header",
      "scale_down"
      ), 
    bootstrap_options = c(
      "hover"
      )
    )
```

## Visualizing the interpolated time series

The **MOISCRUST** database looks as follows after applying the imputation algorithm.

```{r, fig.width=12, fig.height=17, eval = TRUE, echo = TRUE}
ggplot(moiscrust_long) + 
  facet_wrap(
    "year", 
    scales = "free_x", 
    ncol = 2
    ) +
  aes(
    x = year_day, 
    y = sensor, 
    fill = soil_moisture
    ) + 
  geom_tile() + 
  coord_cartesian(expand = FALSE) +
  theme_bw() + 
  scale_fill_viridis_c(
    direction = -1, 
    na.value = "white", 
    option = "B"
    ) +
  theme(legend.position = "top") + 
  ylab("") + 
  xlab("Day of the year") +
  ggtitle("MOISCRUST database (observed and interpolated records)") +
  labs(fill = expression("Volumetric water content (m³ water / m³ soil)")) + 
  theme(legend.key.width = unit(0.8, "cm"))
```

The plot above represents both observed and interpolated values, without a clear differentiation between each type. To provide an indicator of imputation quality, the imputation algorithm also generated a new column named *interpolation_quality*, where the observations are marked with the flag "observation", the imputed data where *x* and *y* shared more than 20% of valid cases and had an R² higher than 0.85 are marked with the flag "acceptable", and the imputed data below these thresholds are marked with the flag "poor". The plot below shows the values of these flags for each sensor and time, year per year.

```{r, fig.width=12, fig.height=17, eval = TRUE, echo = TRUE}
ggplot(moiscrust_long) + 
  facet_wrap(
    "year", 
    scales = "free_x", 
    ncol = 2
    ) +
  aes(
    x = year_day, 
    y = sensor, 
    fill = factor(
      interpolation_quality, 
      levels = c(
        "observation", 
        "acceptable", 
        "poor"
        )
      )
    ) + 
  geom_tile() + 
  coord_cartesian(expand = FALSE) +
  theme_bw() + 
  scale_fill_viridis_d(
    direction = -1, 
    begin = 0.1,
    end = 0.8, 
    na.value = "white", 
    option = "B"
    ) +
  theme(legend.position = "top") + 
  ylab("") + 
  xlab("Day of the year") +
  ggtitle("MOISCRUST database (data quality)") +
  labs(
    fill = expression("Data quality")) + 
  theme(legend.key.width = unit(1, "cm"))
```

# Incorporating weather data at daily resolution

The file `data/daily_weather_aranjuez.csv` contains daily records of solar radiation (daily sum), temperature (maximum and minimum, in ºC), rainfall (daily sum, in mm.), and humidity (in percentage). To join this file with the `moiscrust` dataset, here we import it, aggregate `moiscrust` at daily resolution using only observations, and finally join both datasets by date.

```{r}
#importing the table
weather <- data.table::fread("data/daily_weather_aranjuez.csv") %>%
  as.data.frame()

#formatting date
weather$date <- format(
  as.POSIXct(
    strptime(
      weather$date,
      "%d/%m/%Y",
      tz = ""
    )
  ),
  format = "%Y-%m-%d"
)

#function to compute the mode of a character vector
char_mode <- function(x){
  x.unique <- unique(na.omit(x))
  x.unique[which.max(tabulate(match(x, x.unique)))]
}

#aggregating moiscrust at daily resolution
moiscrust_daily <- moiscrust_long %>% 
  dplyr::group_by(sensor, year, year_day) %>% 
  dplyr::summarise(
    date = date[1],
    month = month[1],
    month_day = month_day[1],
    week = week[1],
    week_day = week_day[1],
    soil_moisture_min = suppressWarnings(min(soil_moisture, na.rm = TRUE)),
    soil_moisture_mean = mean(soil_moisture, na.rm = TRUE),
    soil_moisture_max = suppressWarnings(max(soil_moisture, na.rm = TRUE)),
    interpolated = ifelse(sum(interpolated) > 0, TRUE, FALSE),
    model_estimate = mean(model_estimate, na.rm = TRUE),
    model_ci_lower = mean(model_ci_lower, na.rm = TRUE),
    model_ci_upper = mean(model_ci_upper, na.rm = TRUE),
    model_predictor = char_mode(model_predictor),
    same_microsite = char_mode(same_microsite),
    sensors_shared_valid_percent = mean(sensors_shared_valid_percent, na.rm = TRUE),
    selection_score = mean(selection_score, na.rm = TRUE),
    microsite = microsite[1],
    interpolation_quality = char_mode(interpolation_quality)
  ) %>% 
  as.data.frame()

#NaN to NA
is.nan.data.frame <- function(x){
  do.call(cbind, lapply(x, is.nan))
}
moiscrust_daily[is.nan(moiscrust_daily)] <- NA

#joining by date
moiscrust_weather <- dplyr::left_join(
  moiscrust_daily,
  weather,
  by = "date"
) %>% dplyr::filter(
  interpolated == FALSE
) %>% 
  dplyr::select(
    -contains("model_"),
    -same_microsite,
    -sensors_shared_valid_percent,
    -selection_score,
    -interpolation_quality,
    -year.y,
    -month.y
    ) %>% 
  dplyr::rename(
    year = year.x,
    month = month.x,
    temperature_max = temperature_maximum,
    temperature_min = temperature_minimum
  ) %>% 
  dplyr::transmute(
    date,
    year,
    year_day,
    season,
    month,
    month_day,
    week,
    week_day,
    microsite,
    sensor,
    soil_moisture_min,
    soil_moisture_mean = round(soil_moisture_mean, 3),
    soil_moisture_max,
    solar_radiation_sum,
    temperature_max,
    temperature_min,
    rainfall_sum,
    humidity_average
  ) %>% 
  na.omit()
```

The resulting table, `moiscrust_weather`, has daily observations of soil humidity coupled with daily weather data, and no imputed data.

# Preparing database formats

## Format description

The dataset **moiscrust_long** is the database in long format already. Below we rename it to **moiscrust**, and describe its columns.

```{r}
moiscrust <- moiscrust_long
```

The columns of the `moiscrust` table are:

-   *date_time*: date and time in POSIX format.
-   *date_time_id*: integer, unique ID for each value of *date_time*.
-   *date*: date in format year-month-day.
-   *time*: time in format hour-minute.
-   *year*: integer, year.
-   *year_day*: integer, day of the year.
-   *month*: integer, month number.
-   *week*: integer, week of the year.
-   *week_day*: integer, day of the week.
-   *sensor*: character, sensor name.
-   *soil_moisture*: numeric, soil moisture value in $m^{3} water /m^{3} soil$.
-   *interpolated*: boolean, *TRUE* for interpolated records and *FALSE* for observations.
-   *model_estimate*: numeric, prediction of the linear model.
-   *model_ci_lower*: numeric, lower bound of the confidence interval of the estimate.
-   *model_ci_upper*: numeric, upper bound of the confidence interval of the estimate.
-   *model_predictor*: character, name of the sensor used as predictor in the linear model.
-   *same_microsite*: boolean, *TRUE* if the sensor and its predictor are in the same group ("stipa", "retama", "biocrust_low", "biocrust_medium", "biocrust_high").
-   *sensors_r_squared*: numeric, R squared between *sensor* and *model_predictor*.
-   *sensors_shared_valid_percent*: numeric, percentage of shared valid cases between *sensor* and *model_predictor*, taking the total number of values in *date_time_id* as reference.
-   *selection_score*: numeric, value used to select the *model_predictor*, based on the sum of *same_microsite* (100 if *TRUE* and 0 if *FALSE*), *sensors_r_squared* multiplied by 100, and *sensors_shared_valid_percent*.
-   *interpolation_quality*: character, with the values "observation" for observations, "acceptable" for interpolated values where *sensors_r_squared* is higher than 0.85 and *sensors_shared_valid_percent* is higher than 20, and "poor" for interpolated values below at least one of these thresholds.

## Saving the data base in different formats

To expand its usability as much as possible, we provide the data in four different formats: .RData, .csv, .xlsx, and .db (SQLite). The output files are written first to the `database` folder, that is later compressed and named `database.zip`.

```{r, eval = TRUE}
#if the zip file does not exists, creates database directory and populates it
if(!file.exists("database.zip")){
  
  dir.create("database")
  
  #save as RData
  save(
    moiscrust, 
    moiscrust_weather,
    file = "database/moiscrust.RData"
  )
  
  #save as csv
  readr::write_excel_csv(
    x = moiscrust,
    path = "database/moiscrust.csv"
  )
  readr::write_excel_csv(
    x = moiscrust_weather,
    path = "database/moiscrust_weather.csv"
  )
  
  #save as excel file
  writexl::write_xlsx(
    x = list(
      moiscrust = moiscrust,
      moiscrust_weather = moiscrust_weather
      ),
    path = "database/moiscrust.xlsx"
  )
  
  #save as SQLite
  db.driver <- DBI::dbDriver("SQLite")
  db.connection <-  DBI::dbConnect(
    db.driver, 
    dbname = "database/moiscrust.db"
    )
  DBI::dbWriteTable(
    db.connection, 
    "moiscrust", 
    moiscrust, 
    overwrite = TRUE
    )
    DBI::dbWriteTable(
    db.connection, 
    "moiscrust_weather", 
    moiscrust_weather, 
    overwrite = TRUE
    )
  DBI::dbDisconnect(db.connection)
  
  #compressing the file
  zip::zipr(
    zipfile = "database.zip",
    files = "database"
  )
  
}
```


```{r, echo = FALSE, warning = FALSE, message = FALSE, error = FALSE}
rm(
  db.connection,
  db.driver,
  best_predictor,
  moiscrust_interpolation_long,
  moiscrust_long,
  moiscrust_NA,
  predictor_candidates,
  sensor,
  sensors,
  sensors_pair,
  sensors_pairs,
  sensors_pairs_models,
  x_row,
  weather,
  moiscrust_daily,
  x,
  y
)
```

